{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk,re\n",
    "import tensorflow as tf\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional, Embedding, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam \n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_file(file_name):\n",
    "    X = []\n",
    "    with open(file_name, encoding=\"utf8\") as f:             #StackOverflow.txt\n",
    "        for x in f:\n",
    "            X.append(x)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_X = pd.Series(read_from_file('StackOverflow.txt'))\n",
    "train_data_Y = pd.Series(read_from_file('StackOverflow_gnd.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chaitanyasudarsan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.split()\n",
    "    \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if w not in stop_words]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \"  \", text)\n",
    "    text = re.sub(r\"\\+\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" \", text)\n",
    "    text = re.sub(r\"\\=\", \"  \", text)\n",
    "    text = re.sub(r\"\\:\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    text = text.split()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatize_words = [lemmatizer.lemmatize(word) for word in text]  \n",
    "    text = \" \".join(lemmatize_words)\n",
    "    \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_X = train_data_X.apply(lambda x: clean_text(x))\n",
    "train_data_Y = train_data_Y.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        how i fill dataset datatable linq query resultset\n",
      "1                                 how page collection linq\n",
      "2                best subversion client window vista 64bit\n",
      "3        best practice collaborative environment bin di...\n",
      "4        visual studio setup project per user registry ...\n",
      "5        how i elegantly express left join aggregate sq...\n",
      "6                        net xml comment api documentation\n",
      "7        modify address bar url ajax app match current ...\n",
      "8        integrating visual studio test project cruise ...\n",
      "9        what longtime window user know starting use linux\n",
      "10                   folder project visual studio solution\n",
      "11                                 how i create branch svn\n",
      "12                 add custom tag visual studio validation\n",
      "13         how i turn line number default textwrangler mac\n",
      "14               how tab focus onto dropdown field mac osx\n",
      "15                           how tab button osx dialog box\n",
      "16                                 progressive enhancement\n",
      "17       what good web based grid accepts excel clipboa...\n",
      "18       what keyboard shortcut view open document visu...\n",
      "19               how generate getters setter visual studio\n",
      "20       plugin visual studio mimic eclipse open type o...\n",
      "21       can asp net ajax partial rendering work inside...\n",
      "22                 what best way deploy vb net application\n",
      "23                favorite web app deployment workflow svn\n",
      "24              setup visual studio 2005 print line number\n",
      "25       automated release script visual studio setup p...\n",
      "26       how i configure vista ultimate 64bit account a...\n",
      "27                            svn merge merged extra stuff\n",
      "28          best svn client ignore pattern vb net solution\n",
      "29                 experience svn v team foundation server\n",
      "                               ...                        \n",
      "19970                   how i overide local module magento\n",
      "19971    how get all credit card detail entered custome...\n",
      "19972    magento product selection grid placing order a...\n",
      "19973                       order detail sql query magento\n",
      "19974            magento send email different order status\n",
      "19975          magento 1 5 install mac osx error installer\n",
      "19976                  megento vertnav expand one category\n",
      "19977                        magento database connectivity\n",
      "19978     magento redirecting cart continuing billing info\n",
      "19979                    multi part clothing store magento\n",
      "19980             magento tag wishlist product admin order\n",
      "19981          do not display stock counter bundle product\n",
      "19982       magento adminhtml field depend one field value\n",
      "19983                   is normal magento memory behaviour\n",
      "19984                magento display attribute admin title\n",
      "19985    displaying attribute simple product table grou...\n",
      "19986        magento change catalog input type store owner\n",
      "19987                         preconfigured magento widget\n",
      "19988    anyone know access magento gift card sku trans...\n",
      "19989              magento working paypal express checkout\n",
      "19990    magento filter product collection tier price c...\n",
      "19991    is way refresh magento catalog not shopping ca...\n",
      "19992                  fetch category detail query magento\n",
      "19993    magento wishlist sidebar main view return last...\n",
      "19994                           move magento attribute tab\n",
      "19995                    magento custom option v attribute\n",
      "19996                  how solve 404 found problem magento\n",
      "19997              want add custom option frontend magento\n",
      "19998    installing magento plugins without using magen...\n",
      "19999        magento call member function count non object\n",
      "Length: 20000, dtype: object\n",
      "0        18\n",
      "1        18\n",
      "2         3\n",
      "3         3\n",
      "4         7\n",
      "5        18\n",
      "6         7\n",
      "7        15\n",
      "8         7\n",
      "9        10\n",
      "10        7\n",
      "11        3\n",
      "12        7\n",
      "13        9\n",
      "14        9\n",
      "15        9\n",
      "16       15\n",
      "17        5\n",
      "18        7\n",
      "19        7\n",
      "20        7\n",
      "21       15\n",
      "22        7\n",
      "23        3\n",
      "24        7\n",
      "25        7\n",
      "26        9\n",
      "27        3\n",
      "28        3\n",
      "29        3\n",
      "         ..\n",
      "19970    20\n",
      "19971    20\n",
      "19972    20\n",
      "19973    20\n",
      "19974    20\n",
      "19975    20\n",
      "19976    20\n",
      "19977    20\n",
      "19978    20\n",
      "19979    20\n",
      "19980    20\n",
      "19981    20\n",
      "19982    20\n",
      "19983    20\n",
      "19984    20\n",
      "19985    20\n",
      "19986    20\n",
      "19987    20\n",
      "19988    20\n",
      "19989    20\n",
      "19990    20\n",
      "19991    20\n",
      "19992    20\n",
      "19993    20\n",
      "19994    20\n",
      "19995    20\n",
      "19996    20\n",
      "19997    20\n",
      "19998    20\n",
      "19999    20\n",
      "Length: 20000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data_X)\n",
    "print(train_data_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_len=[]\n",
    "for text in train_data_X:\n",
    "    word=word_tokenize(text)\n",
    "    l=len(word)\n",
    "    sen_len.append(l)\n",
    "    \n",
    "max_sen_len=np.max(sen_len)\n",
    "max_sen_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_no_unique_words(texts_1):\n",
    "    all_words = ' '.join(texts_1)\n",
    "    all_words = word_tokenize(all_words)\n",
    "    dist = FreqDist(all_words)\n",
    "    num_unique_word = len(dist)\n",
    "    return num_unique_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10033"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_unique_word = get_no_unique_words(train_data_X)\n",
    "num_unique_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10033)\n",
    "tokenizer.fit_on_texts(train_data_X)\n",
    "\n",
    "train_data_X_sequences = tokenizer.texts_to_sequences(train_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    how i fill dataset datatable linq query resultset\n",
      "1                             how page collection linq\n",
      "2            best subversion client window vista 64bit\n",
      "3    best practice collaborative environment bin di...\n",
      "4    visual studio setup project per user registry ...\n",
      "5    how i elegantly express left join aggregate sq...\n",
      "6                    net xml comment api documentation\n",
      "7    modify address bar url ajax app match current ...\n",
      "8    integrating visual studio test project cruise ...\n",
      "9    what longtime window user know starting use linux\n",
      "dtype: object\n",
      "[[1, 2, 1177, 969, 1178, 10, 37, 1502], [1, 30, 138, 10], [50, 63, 240, 57, 1306, 1861], [50, 279, 2570, 329, 1244, 90, 24], [18, 20, 408, 74, 449, 51, 2571, 163], [1, 2, 2979, 707, 450, 183, 1307, 38, 10, 37], [62, 79, 342, 217, 869], [560, 477, 518, 85, 15, 112, 343, 263, 351], [895, 18, 20, 188, 74, 2980, 109], [17, 4959, 57, 51, 413, 836, 27, 299]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_X[0:10])\n",
    "print(train_data_X_sequences[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_X_sequences = pad_sequences(train_data_X_sequences, maxlen = max_sen_len)\n",
    "\n",
    "#labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    1    2 1177  969 1178   10   37 1502]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    1   30  138   10]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   50   63  240   57 1306 1861]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   50  279 2570  329 1244   90   24]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   18   20  408   74  449   51 2571  163]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    1    2 2979  707  450  183 1307   38   10   37]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0   62   79  342  217  869]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0  560  477  518   85   15  112  343  263  351]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0  895   18   20  188   74 2980  109]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   17 4959   57   51  413  836   27  299]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_X_sequences[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 28)\n",
      "(20000,)\n",
      "(20000, 21)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_X_sequences.shape)\n",
    "print(train_data_Y.shape)\n",
    "train_data_Y = to_categorical(train_data_Y)\n",
    "print(train_data_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/project/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/project/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         1003300   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 21)                2709      \n",
      "=================================================================\n",
      "Total params: 1,090,489\n",
      "Trainable params: 1,090,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Embedding(num_unique_word,100,mask_zero=True))\n",
    "model1.add(Bidirectional(LSTM(64,dropout=0.4, recurrent_dropout=0.4),merge_mode='concat'))\n",
    "#model1.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "model1.add(Dense(21,activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/project/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 2.0197 - acc: 0.6175\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.5576 - acc: 0.8778\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.3308 - acc: 0.9257\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 3\n",
    "num_classes=21\n",
    "history1=model1.fit(train_data_X_sequences, train_data_Y,epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = model1.layers[-2]\n",
    "target_layer.return_sequences = True\n",
    "target_layer.forward_layer.return_sequences = True\n",
    "target_layer.backward_layer.return_sequences = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ed28d3f91e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_input_at\u001b[0;34m(self, node_index)\u001b[0m\n\u001b[1;32m    714\u001b[0m         return self._get_node_attribute_at_index(node_index,\n\u001b[1;32m    715\u001b[0m                                                  \u001b[0;34m'input_tensors'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                                                  'input')\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    658\u001b[0m             raise RuntimeError('The layer has never been called '\n\u001b[1;32m    659\u001b[0m                                'and thus has no defined ' + attr_name + '.')\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m             raise ValueError('Asked to get ' + attr_name +\n\u001b[1;32m    662\u001b[0m                              \u001b[0;34m' at node '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    651\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \"\"\"\n\u001b[0;32m--> 653\u001b[0;31m     raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\n\u001b[0m\u001b[1;32m    654\u001b[0m                     \u001b[0;34m\"Use `if t is not None:` instead of `if t:` to test if a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;34m\"tensor is defined, and use TensorFlow ops such as \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor."
     ]
    }
   ],
   "source": [
    "outputs = target_layer.get_input_at(target_layer.input)\n",
    "m = Model(model1.input, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
